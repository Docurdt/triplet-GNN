{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98adcdc0-641d-4f86-a633-e412bd003ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP Study 2023 for immunotherapy response prediction\n",
    "# Yanan Wang @ BNR Mar. 27, 2024\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib\n",
    "import argparse\n",
    "from sklearn.metrics import f1_score, accuracy_score, auc, roc_curve\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
    "from model_and_metrics import *\n",
    "from torch.nn import Linear\n",
    "import pandas as pd\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn.conv import GraphConv, GCNConv, GINConv, GATConv\n",
    "from torch_geometric.nn.pool import TopKPooling, SAGPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "import math\n",
    "from pytorchtools import EarlyStopping\n",
    "import optuna\n",
    "from sklearn.utils import shuffle\n",
    "import networkx as nx\n",
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "from torch_geometric.explain.metric import fidelity, unfaithfulness\n",
    "\n",
    "import joblib\n",
    "from tripletnet import Tripletnet\n",
    "# import gnn_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233c851d-da5e-4142-a362-7c246fd50f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())  # 查看cuda是否可用\n",
    " \n",
    "print(torch.cuda.device_count())  # 返回GPU数目\n",
    " \n",
    "print(torch.cuda.get_device_name(0))  # 返回GPU名称，设备索引默认从0开始\n",
    " \n",
    "print(torch.cuda.current_device())  # 返回当前设备索引\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd3c9d0-3a77-4c63-bcd8-256e53a5a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c9648a-63d5-4a1b-bbc0-6c67e39e7779",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df = pd.read_excel('pa_val_split_0.xlsx')\n",
    "ref_df_patient = pd.pivot_table(ref_df, index=['pid'], values=['label', 'preds'], aggfunc='mean') #pid\tsplit\tlabel\tpreds\n",
    "\n",
    "ref_df_patient = ref_df_patient[((ref_df_patient.preds > 0.65) & (ref_df_patient.label == 1)) | ((ref_df_patient.preds < 0.35) & (ref_df_patient.label == 0))]\n",
    "\n",
    "print(ref_df_patient.shape)\n",
    "ref_df_patient.head()\n",
    "ref_patients = ref_df_patient.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874ae6a8-d9eb-416e-9990-25885a22f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(edge_index, edge_attr):\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # G.add\n",
    "    #G.add_nodes_from(coor[0])\n",
    "\n",
    "    edge_index_tmp = np.array(edge_index[:,0:100],dtype=int)\n",
    "    print(edge_index_tmp)\n",
    "\n",
    "    # G.add_edges_from(edge_index_tmp)\n",
    "\n",
    "    for i in range(len(edge_index_tmp)):\n",
    "        G.add_edge(edge_index_tmp[i, 0], edge_index_tmp[i, 1], weight=edge_attr[i][0])\n",
    "\n",
    "\n",
    "    elarge = [(u, v) for (u, v, d) in G.edges(data=True) if d[\"weight\"] > 2]\n",
    "    esmall = [(u, v) for (u, v, d) in G.edges(data=True) if d[\"weight\"] <= 2]\n",
    "\n",
    "    pos = nx.spring_layout(G, seed=7)\n",
    "    # nodes\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=20)\n",
    "\n",
    "    # edges\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=elarge, edge_color=\"r\", width=2)\n",
    "    nx.draw_networkx_edges(\n",
    "       G, pos, edgelist=esmall, width=0.5, alpha=0.5, edge_color=\"gray\", style=\"dashed\"\n",
    "    )\n",
    "\n",
    "    # node labels\n",
    "    #nx.draw_networkx_labels(G, pos, font_size=2, font_family=\"sans-serif\")\n",
    "    # edge weight labels\n",
    "    #edge_labels = nx.get_edge_attributes(G, \"weight\")\n",
    "    #nx.draw_networkx_edge_labels(G, pos, edge_labels)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.margins(0.01)\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # plt.savefig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7ebff5-d1f1-4d49-8487-c9f60cf5bc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build the model\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, nhid=128, gnn_layer='GCN', drop_out=0.5, num_feature = joblib.load('data/pa_num_feature.joblib')):\n",
    "        super(GNN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.nhid=nhid\n",
    "        self.num_feature = num_feature\n",
    "        self.drop_out = drop_out\n",
    "        self.adp = torch.nn.AlphaDropout(p=self.drop_out)\n",
    "        self.bn = torch.nn.BatchNorm1d(self.nhid)\n",
    "        self.elu = torch.nn.ELU()\n",
    "        \n",
    "        if(gnn_layer=='GCN'):\n",
    "            self.conv1 = GraphConv(self.num_feature, self.nhid)\n",
    "            self.conv2 = GraphConv(self.nhid, self.nhid//2)\n",
    "            self.conv3 = GraphConv(self.nhid//2, self.nhid//4)\n",
    "        elif(gnn_layer=='GAT'):\n",
    "            self.conv1 = GATConv(int(self.num_feature), self.nhid)\n",
    "            self.conv2 = GATConv(self.nhid, self.nhid//2)\n",
    "            self.conv3 = GATConv(self.nhid//2, self.nhid//4)\n",
    "        elif(gnn_layer=='GIN'):\n",
    "            self.conv1 = GINConv(Seq(Lin(self.num_feature, self.nhid), ReLU(), Lin(self.nhid, self.nhid)))\n",
    "            self.conv2 = GINConv(Seq(Lin(self.nhid, self.nhid//2), ReLU(), Lin(self.nhid//2, self.nhid//2)))\n",
    "            self.conv3 = GINConv(Seq(Lin(self.nhid//2, self.nhid//4), ReLU(), Lin(self.nhid//4, self.nhid//4))) \n",
    "            \n",
    "        self.linear_1 = Linear(self.nhid//2, self.nhid//4)\n",
    "        self.linear_2 = Linear(self.nhid//4, self.nhid//8)\n",
    "        # self.linear_3 = Linear(self.nhid//2, 2)\n",
    "        # self.linear_1 = Linear(self.nhid//2, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch=torch.tensor([0])):\n",
    "        # print(batch)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn(x)\n",
    "        x = self.elu(x)\n",
    "        #x = self.adp(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        #x = self.bn(x)\n",
    "        x = self.elu(x)\n",
    "        # x = self.adp(x)\n",
    "        # x = self.conv3(x, edge_index)\n",
    "        # x = self.bn(x)\n",
    "        # x = self.elu(x)\n",
    "        # x = self.adp(x)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        #x = (x - torch.min(x))/(torch.max(x) - torch.min(x))\n",
    "\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        x = self.linear_1(x)\n",
    "        x = self.linear_2(x)\n",
    "        # x = self.linear_3(x)\n",
    "        y = F.sigmoid(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d868e41-6804-456e-8bc3-fb9a4d8bbb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_data_load_train(tmp_data_list):\n",
    "    triplet_data = []\n",
    "    print(\"Overall sample size: %d\" % len(tmp_data_list))\n",
    "    pos_x_idx = []\n",
    "    pos_y_idx = []\n",
    "    neg_z_idx = []\n",
    "    for i in range(len(tmp_data_list)):\n",
    "        # print(tmp_data_list[i].y.cpu().numpy())\n",
    "        if(tmp_data_list[i].y.cpu().numpy()[0][0] == 1):\n",
    "            neg_z_idx.append(i)\n",
    "        else:\n",
    "            pos_x_idx.append(i)\n",
    "            pos_y_idx.append(i)\n",
    "            \n",
    "    print(len(neg_z_idx))\n",
    "    print(len(pos_x_idx))\n",
    "    max_sample_size = max(len(pos_x_idx), len(neg_z_idx))\n",
    "    print(max_sample_size)\n",
    "    pos_x_idx = np.random.choice(pos_x_idx, max_sample_size*5, replace=True)\n",
    "    pos_y_idx = np.random.choice(pos_y_idx, max_sample_size*5, replace=True)\n",
    "    neg_z_idx = np.random.choice(neg_z_idx, max_sample_size*5, replace=True)\n",
    "    while(np.any((pos_x_idx-pos_y_idx)==0)):\n",
    "        np.random.shuffle(pos_y_idx)\n",
    "    \n",
    "    for j in range(max_sample_size):\n",
    "        triplet_data.append([tmp_data_list[pos_x_idx[j]], tmp_data_list[pos_y_idx[j]], tmp_data_list[neg_z_idx[j]]])\n",
    "        \n",
    "    return triplet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36277c27-7323-46cc-b98d-ef4e8ce258db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_data_load(tmp_data_list):\n",
    "    triplet_data = []\n",
    "    print(\"Overall sample size: %d\" % len(tmp_data_list))\n",
    "    pos_x_idx = []\n",
    "    pos_y_idx = []\n",
    "    neg_z_idx = []\n",
    "    for i in range(len(tmp_data_list)):\n",
    "        # print(tmp_data_list[i].y.cpu().numpy())\n",
    "        if(tmp_data_list[i].y.cpu().numpy()[0][0] == 1):\n",
    "            neg_z_idx.append(i)\n",
    "        else:\n",
    "            pos_x_idx.append(i)\n",
    "            pos_y_idx.append(i)\n",
    "            \n",
    "    print(len(neg_z_idx))\n",
    "    print(len(pos_x_idx))\n",
    "    # max_sample_size = max(len(pos_x_idx), len(neg_z_idx))\n",
    "    max_sample_size = len(pos_x_idx) + len(neg_z_idx)\n",
    "    print(max_sample_size)\n",
    "    pos_x_idx = np.random.choice(range(max_sample_size), max_sample_size, replace=True)\n",
    "    pos_y_idx = np.random.choice(pos_y_idx, max_sample_size, replace=True)\n",
    "    neg_z_idx = np.random.choice(neg_z_idx, max_sample_size, replace=True)\n",
    "    while(np.any((pos_x_idx-pos_y_idx)==0)):\n",
    "        np.random.shuffle(pos_y_idx)\n",
    "    \n",
    "    for j in range(max_sample_size):\n",
    "        triplet_data.append([tmp_data_list[pos_x_idx[j]], tmp_data_list[pos_y_idx[j]], tmp_data_list[neg_z_idx[j]]])\n",
    "        \n",
    "    return triplet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8544569-806e-4142-8a35-d5c75ce54c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_data_load_ex_test(train_list, tmp_data_list):\n",
    "    triplet_data = []\n",
    "    print(\"Overall sample size: %d\" % len(tmp_data_list))\n",
    "    pos_x_idx = []\n",
    "    pos_y_idx = []\n",
    "    neg_z_idx = []\n",
    "    for i in range(len(train_list)):\n",
    "        # print(tmp_data_list[i].y.cpu().numpy())\n",
    "        if(train_list[i].y.cpu().numpy()[0][0] == 1):\n",
    "            neg_z_idx.append(i)\n",
    "        else:\n",
    "            # pos_x_idx.append(i)\n",
    "            pos_y_idx.append(i)\n",
    "            \n",
    "    print(len(neg_z_idx))\n",
    "    print(len(pos_y_idx))\n",
    "    max_sample_size = len(tmp_data_list) #max(len(pos_x_idx), len(neg_z_idx))\n",
    "    print(max_sample_size)\n",
    "    #pos_x_idx = np.random.choice(pos_x_idx, max_sample_size*5, replace=True)\n",
    "    pos_y_idx = np.random.choice(pos_y_idx, max_sample_size, replace=True)\n",
    "    neg_z_idx = np.random.choice(neg_z_idx, max_sample_size, replace=True)\n",
    "    # while(np.any((pos_x_idx-pos_y_idx)==0)):\n",
    "    #     np.random.shuffle(pos_y_idx)\n",
    "    \n",
    "    for j in range(max_sample_size):\n",
    "        triplet_data.append([tmp_data_list[j], train_list[pos_y_idx[j]], train_list[neg_z_idx[j]]])\n",
    "        \n",
    "    return triplet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2f352c-0275-447c-a795-731459a6f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_list(ori_list, split_info, ex_list, fold=0):\n",
    "    tmp_col_id = split_info.columns.get_loc(\"split_{}\".format(fold))\n",
    "    \n",
    "    train_list = []\n",
    "    val_list = []\n",
    "    test_list = []\n",
    "    ex_test_list = []\n",
    "    \n",
    "    train_ids = list(split_info[split_info.iloc[:, tmp_col_id] == 'Train'].sample_id)\n",
    "    val_ids = list(split_info[split_info.iloc[:, tmp_col_id] == 'Validate'].sample_id)\n",
    "    test_ids = list(split_info[split_info.iloc[:, tmp_col_id] == 'Test'].sample_id)\n",
    "    # print(val_ids)\n",
    "    for i in range(len(ori_list)):\n",
    "        tmp_data = ori_list[i]\n",
    "        pid_temp = [chr(x) for x in list(tmp_data.pid.cpu().numpy()[0])]\n",
    "        pid_temp = \"\".join(pid_temp)\n",
    "        # print(pid_temp)\n",
    "        if(pid_temp in train_ids):\n",
    "            train_list.append(tmp_data)\n",
    "        elif(pid_temp in val_ids):\n",
    "            val_list.append(tmp_data)\n",
    "        elif(pid_temp in test_ids):\n",
    "            test_list.append(tmp_data)\n",
    "            \n",
    "    train_tri_data = triplet_data_load_train(train_list)\n",
    "    val_tri_data_train = triplet_data_load_train(val_list)\n",
    "    val_tri_data_test = triplet_data_load(val_list)\n",
    "    test_tri_data = triplet_data_load(test_list)\n",
    "    ex_test_tri_data = triplet_data_load_ex_test(train_list, ex_list)\n",
    "    \n",
    "    return(train_tri_data, val_tri_data_train, val_tri_data_test, test_tri_data, ex_test_tri_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550be1ca-8de7-4365-8635-10d3c5eadc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function:\n",
    "# Input: model and test loader;\n",
    "# Output: Index, Sample_ID, Label, Embeded, distance_a, distance_b, pred;\n",
    "\n",
    "def test(model, loader, target_dir):\n",
    "    model.eval()\n",
    "    criterion = torch.nn.TripletMarginLoss()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #device = torch.device('cuda:2')\n",
    "    loss = 0       \n",
    "    label = np.array([])\n",
    "    p_id = []\n",
    "    tile_index = []\n",
    "    dist_a_all = []\n",
    "    dist_b_all = []\n",
    "    \n",
    "    embedded_output = np.array([])\n",
    "    \n",
    "    for i, data in enumerate(loader):\n",
    "        tile_index.append(i)\n",
    "        dist_a, dist_b, embedded_x, embedded_y, embedded_z = model(data[0], data[1], data[2])\n",
    "        \n",
    "        dist_a_all.append(float(dist_a.cpu().detach()))\n",
    "        dist_b_all.append(float(dist_b.cpu().detach()))\n",
    "        \n",
    "        pid_temp = [chr(x) for x in list(data[0].pid.cpu().numpy()[0])]\n",
    "        pid_temp = \"\".join(pid_temp)\n",
    "        p_id.append(pid_temp)\n",
    "        \n",
    "        loss += criterion(embedded_x, embedded_y, embedded_z).item()\n",
    "\n",
    "        _tmp_label = data[0].y.cpu().detach().numpy()[:, 1]\n",
    "\n",
    "        label = np.hstack([label,_tmp_label]) if label.size else _tmp_label\n",
    "        embedded_output = np.hstack([embedded_output,embedded_x.cpu().detach().numpy()]) if embedded_output.size else embedded_x.cpu().detach().numpy()\n",
    "        # print(label)\n",
    "    # pred_1 = np.array(pred_1).reshape(pred_1)\n",
    "    acc_trip = accuracy(dist_a_all, dist_b_all)\n",
    "    trip_auc = triplet_auc(dist_a_all, dist_b_all, label, target_dir)\n",
    "    # print(acc_trip)\n",
    "    return tile_index, p_id, label, embedded_output, dist_a_all, dist_b_all, loss / len(loader.dataset), trip_auc, acc_trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3388f853-e770-4c02-a716-e4a56e475ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(dista, distb):\n",
    "    # print(dista)\n",
    "    margin = 0\n",
    "    pred = (np.array(dista) - np.array(distb) - margin)\n",
    "    # print(pred)\n",
    "    return (pred < 0).sum()*1.0/len(dista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d2db8-e315-46c2-90b9-123697e2c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_auc(dista, distb, label, target_dir):\n",
    "        # print(dista)\n",
    "    margin = 0\n",
    "    pred = (np.array(distb) - np.array(dista) - margin)\n",
    "    pred_norm = (pred-min(pred)) / (max(pred) - min(pred))\n",
    "    \n",
    "    colors = [\"#E69F00\", \"#56B4E9\"]\n",
    "    plt.close('all')\n",
    "    plt.style.use(\"ggplot\")\n",
    "    matplotlib.rcParams['font.family'] = \"Arial\"\n",
    "    plt.figure(figsize=(8, 8), dpi=400)\n",
    "\n",
    "\n",
    "    _fpr, _tpr, _ = roc_curve(label, pred)\n",
    "    _auc = auc(_fpr, _tpr)\n",
    "    plt.plot(_fpr, _tpr, color=colors[0], label=r'%s ROC (AUC = %0.3f)' % (\"MPR\", _auc), lw=2, alpha=.9)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([-0.01, 1.01])\n",
    "    plt.ylim([-0.01, 1.01])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    #plt.title('ROC curve of')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('%s/roc_auc_fig_sample_%d'%(target_dir, len(label)), dpi=400)\n",
    "    plt.close('all')\n",
    "    return(_auc)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf295cd4-f3b8-4ddf-aedf-c6190befc24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(test_loader, panel='pa', fold=0, split=0, batch_size=32, gnn_layer='GAT', \\\n",
    "               dropout_ratio=0.7, nhid=256, learning_rate = 1e-3, \\\n",
    "               weight_decay=1e-5, epochs=300, result_dir = 'pa_pan_results', runs=1):\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #device = torch.device('cuda:2')\n",
    "    ############################# Create folders ##################################\n",
    "\n",
    "    target_dir = \"Visualization_analysis_PA/%s_%s%d_%d_%.3f_%.3f_%.3f_%d_%d\" % (result_dir, gnn_layer, nhid, batch_size, dropout_ratio, learning_rate, weight_decay, split, fold)\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "    print(target_dir)\n",
    "    ###############################################################\n",
    "    num_class = 2\n",
    "    # patience = 30\n",
    "    # train_loss = np.zeros((runs,epochs),dtype=float)\n",
    "    val_acc = np.zeros((runs,epochs))\n",
    "    val_loss = np.zeros((runs,epochs))\n",
    "    val_loss_c = np.zeros(runs)\n",
    "    test_acc_c = np.zeros(runs)\n",
    "    test_loss_c = np.zeros(runs)\n",
    "    test_pred_c = np.zeros(runs)\n",
    "    test_out_c = np.zeros((runs,num_class)) \n",
    "    groud_truth_c = np.zeros((runs,num_class))\n",
    "    test_acc_p = np.zeros(runs)\n",
    "    min_loss = 1e10*np.ones(runs)\n",
    "    \n",
    "    # criterion = torch.nn.BCELoss()\n",
    "    criterion = torch.nn.TripletMarginLoss()\n",
    "\n",
    "\n",
    "    val_t_acc = 0\n",
    "\n",
    "    base_model = GNN(nhid=nhid, gnn_layer=gnn_layer, drop_out=dropout_ratio).to(device)\n",
    "    model = Tripletnet(base_model)\n",
    "    model.load_state_dict(torch.load(\"optimal_model/split_{}/model_fold{}_run{}.pth\".format(split, fold, 0)))\n",
    "    # print(model)\n",
    "#########\n",
    "    #v_tile_index, v_p_id, v_label, v_embedded_output, v_dist_a_all, v_dist_b_all, v_loss_1, v_auc, v_acc = test(model, val_loader_test, target_dir)     \n",
    "    t_tile_index, t_p_id, t_label, t_embedded_output, t_dist_a_all, t_dist_b_all, t_loss_1, t_auc, t_acc = test(model, test_loader, target_dir)\n",
    "\n",
    "    sv = target_dir+'/model_test' + '_fold' + str(fold) + '_runs' + str(runs) + '_run' + str(0) + '_epochs' + str(epochs)+'.mat'\n",
    "\n",
    "    sio.savemat(sv, mdict={'test_index': t_tile_index, 'test_sample_id': t_p_id, 'test_label': t_label, 'test_embedded': t_embedded_output, \n",
    "                           'test_dist_a': t_dist_a_all, 'test_dist_b': t_dist_b_all, 'test_loss': t_loss_1, 'test_auc':t_auc})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500ed169-f02c-4138-ad1b-316aaefd4f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0\n",
    "panel = 'pa'\n",
    "split_info = pd.read_excel('sample_info_split_%d.xlsx' % split)\n",
    "print(split_info.shape)\n",
    "split_info.Response.hist()\n",
    "gnn_data_list = joblib.load('data/%s_data_list.joblib' % panel)\n",
    "ex_gnn_data_list = joblib.load('data/%s_data_list.joblib' % panel)\n",
    "\n",
    "\n",
    "train_list, val_list, val_list_test, test_list, ex_test_list = get_cv_list(gnn_data_list, split_info, ex_gnn_data_list)\n",
    "test_loader = DataLoader(test_list, batch_size=1, shuffle = False)\n",
    "ex_test_loader = DataLoader(ex_test_list, batch_size=1, shuffle = False)\n",
    "\n",
    "print(train_list[0])\n",
    "print(ex_test_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b96151-9c40-4160-b54e-d964fbb586b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(ex_test_loader):\n",
    "    \n",
    "    if(i == 100):\n",
    "        print(f\"Index: {i}\")\n",
    "        # print(data[0], data[1], data[2])\n",
    "        \n",
    "        pid_temp = [chr(x) for x in list(data[0].pid.cpu().numpy()[0])]\n",
    "        pid_temp = \"\".join(pid_temp)\n",
    "        print(pid_temp)\n",
    "        print(data[0].y)\n",
    "        print(data[1].y)\n",
    "        print(data[2].y)\n",
    "        fig = plt.figure()\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(data[0].x.cpu().numpy(), interpolation=\"bicubic\")\n",
    "        plt.subplot(132)\n",
    "        plt.imshow(data[1].x.cpu().numpy(), interpolation=\"bicubic\")\n",
    "        plt.subplot(133)\n",
    "        plt.imshow(data[2].x.cpu().numpy(), interpolation=\"bicubic\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aa126b-9ee3-4175-87a2-d1f75e505962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split = 0\n",
    "panel = 'pa'\n",
    "\n",
    "study = optuna.create_study(\n",
    "        storage=\"sqlite:///db_PA_0606-Copy1.sqlite3\",  # Specify the storage URL here.\n",
    "        study_name=\"GNN_PA_test_0606\", load_if_exists=True)\n",
    "optimal_param = study.best_params\n",
    "#optimal_param = {'batch_size': 64, 'dropout_ratio': 0.3264115110664789, 'gnn_layer': 'GAT', 'learning_rate': 1e-02, 'nhid': 256, 'weight_decay': 1e-05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d4f1c4-a4cc-47ff-bf6c-ebf64c17f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(ex_test_list, \"Visualization_analysis_PA/ex_test_list_fold_0.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0542ffda-4abd-4f38-9c52-c527ccad1cb0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_num = 0\n",
    "\n",
    "for fold_num in range(5):\n",
    "    print(f\"Fold number: {fold_num}\")\n",
    "    model_test(ex_test_loader, panel=panel, fold=fold_num, split=split_num, epochs=300, result_dir = '%s_pan_results_split_%d_fold_%d' % (panel, split_num, fold_num), **optimal_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079e36a9-d10c-4f9f-9246-73d49e98445d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = 1\n",
    "split_num = split\n",
    "\n",
    "for fold_num in range(5):\n",
    "    model_test(ex_test_loader, panel=panel, fold=fold_num, split=split_num, epochs=300, result_dir = '%s_pan_results_split_%d_fold_%d' % (panel, split_num, fold_num), **optimal_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15897caf-6d24-4db5-a9e1-fd54b89f0350",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = 2\n",
    "split_num = split\n",
    "\n",
    "for fold_num in range(5):\n",
    "    model_test(ex_test_loader, panel=panel, fold=fold_num, split=split_num, epochs=300, result_dir = '%s_pan_results_split_%d_fold_%d' % (panel, split_num, fold_num), **optimal_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f04f0-96e9-4109-b020-30aa8d4d04a1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = 3\n",
    "split_num = split\n",
    "\n",
    "for fold_num in range(5):\n",
    "    model_test(ex_test_loader, panel=panel, fold=fold_num, split=split_num, epochs=300, result_dir = '%s_pan_results_split_%d_fold_%d' % (panel, split_num, fold_num), **optimal_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af468f-3eed-47dc-a75f-95d4ac52f3b8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = 4\n",
    "split_num = split\n",
    "\n",
    "for fold_num in range(5):\n",
    "    model_test(ex_test_loader, panel=panel, fold=fold_num, split=split_num, epochs=300, result_dir = '%s_pan_results_split_%d_fold_%d' % (panel, split_num, fold_num), **optimal_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fecbe8-0d3b-4e03-b42b-84209b67dd10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_kernel",
   "language": "python",
   "name": "new_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
